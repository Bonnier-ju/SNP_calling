#!/bin/bash
#SBATCH -p workq
#SBATCH --time=48:00:00 #job time limit
#SBATCH -J 04.2-data_aggregation #job name
#SBATCH -o /work/user/jbonnier/Dicorynia/full_workflow/00-batch_scripts/output/output-%x-%j.out #output file name
#SBATCH -e /work/user/jbonnier/Dicorynia/full_workflow/00-batch_scripts/error/error-%x-%j.out #error file name
#SBATCH --mem=10G #memory reservation
#SBATCH --cpus-per-task=7 #ncpu on the same node
#SBATCH --mail-user=julien.bonnier@ecofog.gf 
#SBATCH --mail-type=END,FAIL



######## Variant calling ########

#`GATK` (Genome Analysis ToolKit) properly pronounced "Gee-ay-tee-kay" (/dʒi•eɪ•ti•keɪ/) and not "Gat-kay" (/ɡæt•keɪ/) 
# has apparently similar performance to other variant callers. 
# 3 steps (following Sylvain Schmitt "Symcapture") 
# 1. Variant calling__ Run the `HaplotypeCaller` on each sample's BAM files to create single-sample gVCFs using the `.g.vcf` extension for the output file.
# 2. Data aggregation__ Aggregate the GVCF files and feed in one GVCF with `GenomicsDBImport` to be genotyped
# 3. Joint genotyping__ Run `GenotypeGVCFs` on all of them together to create the raw SNP and indel VCFs that are usually emitted by the callers.



###Data aggregation with GenomicsDBImport ###
#GVCFs are consolidated into a GenomicsDB datastore in order to improve scalability and speedup the next step: joint genotyping.
#We normally recommend running jobs with 70%-80% efficiency. Based on the efficiency calculated GenomicsDBImport should be run with no more than 2 threads.
#As for memory, increasing memory didn’t improve performance (best 6G, following graph from nih.gov)

#GenomicsDB is a utility built on top of TileDB. TileDB is a format for efficiently representing sparse data. 
#Genomics data is typically sparse in that each sample has few variants with respect to the entire reference genome. 
#GenomicsDB contains code to specialize TileDB for genomics applications, such as VCF parsing and INFO field annotation calculation.


# Clean work place 
module purge 

# Loading modules 
module load devel/python/Python-3.11.1 devel/java/17.0.6
module load bioinfo/GATK/4.2.6.1
module load bioinfo/samtools/1.19

# Define paths
GVCF_DIR=~/work/Dicorynia/full_workflow/04-calling_variants/04.1-haplotype_caller_files/
AGGREGATION_DIR=~/work/Dicorynia/full_workflow/04-calling_variants/04.2-data_aggregation/
REF_GENOME=~/work/Dicorynia/Raw_data/Dgu_HS1_HYBRID_SCAFFOLD.fa
SAMPLE_MAP="${AGGREGATION_DIR}sample_map.txt"
DB_PATH="${AGGREGATION_DIR}GenomicsDB"
TMP_DIR="${AGGREGATION_DIR}tmp"
SEQ_LIST="${AGGREGATION_DIR}reference.sequences.list"

# Ensure output directories exist
mkdir -p "$AGGREGATION_DIR"
mkdir -p "$DB_PATH"
mkdir -p "$TMP_DIR"

### Create sample map ### 
echo -n "" > "$SAMPLE_MAP"

for file in ${GVCF_DIR}*.g.vcf.gz; do 
   echo -e $(basename "${file}" .g.vcf.gz)"\t${file}" >> "$SAMPLE_MAP"
done

echo "Sample map created at $SAMPLE_MAP"

### Create list of reference sequences ###
cut -f1 "${REF_GENOME}.fai" > "$SEQ_LIST"
echo "Reference sequences list created at $SEQ_LIST"

### Data aggregation with GenomicsDBImport ###
echo "Starting GenomicsDBImport..."
gatk --java-options "-Xmx6g -Xms6g" GenomicsDBImport \
     --genomicsdb-workspace-path "${DB_PATH}/my_database" \
     --batch-size 10 \
     -L "$SEQ_LIST" \
     --sample-name-map "$SAMPLE_MAP" \
     --tmp-dir "$TMP_DIR" \
     --reader-threads 5 

echo "GenomicsDBImport completed."
